## Выводы по ДЗ


### Что было сделано?


## Предобработка


№
В процессе подготовки к анализу было проведено:
- удаление дубликатов, 
- удалили с фичей (`mileage`, `engine`, `max_power`) единицы измерения, чтобы их можно было переиспользовать в качестве числовых фичей
- заполнение медианами пропущенных значений с помощью кастомного класса трансформера (вспомнили как это писать)


## EDA
В ходе анализа данных мы выявили основные зависимости между данными: 
- Оценили средние и медианы по числовым фичам, моды по категориальным
- Построили диаграммы рассеяния между признаками. Выдвинули предположения о наличии связей между признаками:

**Прямая:**
1. `max_power` - `selling_price`

**Обратная:**
2. Пробег `km_driven` - `selling_price`
3. Цена `year` - `selling_price`

- Также провели корреляционный анализ между числовыми фичам, где подтвердили наши предположения
Прямая корреляция:
- `max_power` (Мощность) и `selling_price` стоимость (0.69) - сильная
- `engine` (Объем двигателя) и `selling_price` стоимость (0.45)
- `year` (год) и `selling_price` (чем раньше была выпущена машина, тем меньше её цена) (0.43)
- `mileage` (потребление топлива) и `year` год (0.34)

Обратная корреляция:
- `km_driven` и `year` (-0.37) (чем раньше была выпущена машина, тем больше она проехала)
- `engine` и `mileage` (-0.57)
- `max_power` и `mileage` (-0.37) # Чем больше 
- `seats` и `mileage` (-0.37)



## Обучение моделей

Было обучено в общей совокупности 4 уникальных модели, всего - 8

### Модели на числовых фичах
Для моделей Lasso, ElasticNet, LinearRegression использовались только числовые признаки. Они оказались схожи по качеству R2 (от 56 до 59 %)

Для моделей Lasso, ElasticNet был произведен тюнинг гиперпараметров по сетке на 10 фолдах

Также произведены доп. эксперименты по разной стандартизации признаков для модели Lasso: 
- Было выявлено зануление признака `seats`, если отсуствует стандартизация.
- Однако при разной предобработке различие в качестве на тесте оказалось несущественным

Их метрики можно посмотреть в таблице ниже - они похожи по метрикам, несмотря на разные подходы к регуляризации.

### Модели на числовых фичах + категорияальных

Тут мы использовали категориальных кодирование признаков с помощью OneHotEncoder + StandardScaler для обучения `Ridge`

Было осуществлено тестирование feature enginering категориальных фичей и признака `name` в двух вариантах - без него, до бренда, до бренда + модель.

Получившиеся модели:

- RidgeCatCV (обучена только на категориальных) дала прирост R2 до 63%, что можно считать значимым улучшением.

- RidgeCatBrandCV (обучена на категориальных + производителях) дала прирост R2 до 78%
- 
- RidgeBrandModelCV (обучена на категориальных + моделях автомобилей (модель эксперт авторынка)) дала прирост R2 до 90%


### Выводы по обучениею

Таким образом, наилучшее качество получилось у тех моделей, что учились на категориальных признаках + числовых фичах.

Наилучшее качество по всем метрикам у модели `RidgeBrandModelCV`, однако это экспертная модель, которая может опираться на среднюю стоимость авто. 
Поэтому мы первоначально выбрали средний вариант - на производителях
Её метрики: R2 = 78%, mape = 43%, бизнес-метрика - 30%

UPD: для UI красивее будет смотреть с овер метриками, поэтому взял её по итогу :)


Все метрики по моделям с бизнес-метриками (positive_10) приведены в таблице ниже:

|    | model                      |   r2_score |         mse |   rmse |     mape |   positive_10 |   positive_20 |   positive_30 |
|---:|:---------------------------|-----------:|------------:|-------:|---------:|--------------:|--------------:|--------------:|
|  8 | RidgeCatCVWithModels       |   0.912671 | 5.01992e+10 | 224052 | 0.331368 |         0.355 |         0.579 |         0.718 |
|  7 | RidgeCatCVWithBrand        |   0.780766 | 1.26022e+11 | 354996 | 0.437167 |         0.305 |         0.493 |         0.643 |
|  6 | RidgeCatCV                 |   0.633762 | 2.10524e+11 | 458829 | 0.561326 |         0.247 |         0.417 |         0.547 |
|  5 | ElasticNetCV               |   0.562933 | 2.51238e+11 | 501237 | 0.585809 |         0.244 |         0.449 |         0.57  |
|  0 | LinearRegressionWithScaler |   0.565904 | 2.49531e+11 | 499531 | 0.594405 |         0.24  |         0.445 |         0.567 |
|  1 | LassoStd                   |   0.565902 | 2.49532e+11 | 499531 | 0.594402 |         0.24  |         0.445 |         0.567 |
|  4 | LassoCV                    |   0.565902 | 2.49532e+11 | 499531 | 0.594402 |         0.24  |         0.445 |         0.567 |
|  2 | LassoWithoutScaler         |   0.594781 | 2.32931e+11 | 482630 | 0.621295 |         0.22  |         0.421 |         0.546 |
|  3 | LassoMinMaxScaler          |   0.594762 | 2.32943e+11 | 482641 | 0.621286 |         0.22  |         0.421 |         0.546 |


# Приложение

Для приложения мы выбрали пайплайн на моделях автомобилей. Также создали доп. файлы:

- cat_features.json - для аннотаций некоторых категориальных фичей
- cars_test.csv - для загрузки файла из репозитория
- model.pkl - сериализованный пайплайн

Также нам понадобилось перенести часть классов в pkg.py для корректной загрузки пайплайна с кастомными классами SklearnTransformer.

Приложение Streamlit запускается из root директории проекта командой

```shell
streamlit run hw01/app.py
```

Или через Makefile:

```shell
run.hw01
```

## Послесловие

- Понравилось писать кастомные классы, переиспользовать части DS-кода
- Нужно было ещё обучить Ridge без обработки name (UPD: сделано)
- Ещё нужно пробовать бустинги
- Тяжело оценить трудозатраты было и сроки по домашке, домашка большая, а каждое улучшение притягивает желание сделать ещё :). Но это не претензия, получилось круто!

